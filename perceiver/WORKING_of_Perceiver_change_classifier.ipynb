{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " When you run this, it will download the perceiver model from github. Along with the train folder containing the `experiment.py` and `dataset.py`\n",
        "\n",
        "* Folders can be seen on the left hand side of the screen \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n2nWIlJLA7Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdBB_qPu91fU",
        "outputId": "c03e2e4f-ea0f-4e7e-dc3f-5a79ee46a41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.100.202:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.100.202:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQU_paa7QnDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2266f04e-9549-418c-91ef-03b6e00f5d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.7-py3-none-any.whl (342 kB)\n",
            "\u001b[K     |████████████████████████████████| 342 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.2.0)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.7 jmp-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "--2022-07-24 16:11:00--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29359 (29K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/io_processors.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  28.67K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-07-24 16:11:00 (16.8 MB/s) - ‘/content/perceiver/io_processors.py’ saved [29359/29359]\n",
            "\n",
            "--2022-07-24 16:11:00--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30179 (29K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/perceiver.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  29.47K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-07-24 16:11:00 (11.6 MB/s) - ‘/content/perceiver/perceiver.py’ saved [30179/30179]\n",
            "\n",
            "--2022-07-24 16:11:00--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8107 (7.9K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/position_encoding.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]   7.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-24 16:11:01 (56.4 MB/s) - ‘/content/perceiver/position_encoding.py’ saved [8107/8107]\n",
            "\n",
            "--2022-07-24 16:11:01--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/autoaugment.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25589 (25K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/train/autoaugment.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  24.99K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-07-24 16:11:01 (14.0 MB/s) - ‘/content/perceiver/train/autoaugment.py’ saved [25589/25589]\n",
            "\n",
            "--2022-07-24 16:11:01--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14996 (15K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/train/dataset.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  14.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-24 16:11:01 (28.6 MB/s) - ‘/content/perceiver/train/dataset.py’ saved [14996/14996]\n",
            "\n",
            "--2022-07-24 16:11:01--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/experiment.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18810 (18K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/experiment.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]  18.37K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-07-24 16:11:02 (20.2 MB/s) - ‘/content/perceiver/experiment.py’ saved [18810/18810]\n",
            "\n",
            "--2022-07-24 16:11:02--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7940 (7.8K) [text/plain]\n",
            "Saving to: ‘/content/perceiver/train/utils.py’\n",
            "\n",
            "/content/perceiver/ 100%[===================>]   7.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-24 16:11:02 (73.8 MB/s) - ‘/content/perceiver/train/utils.py’ saved [7940/7940]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaxline\n",
            "  Downloading jaxline-0.0.5.tar.gz (32 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.2.0)\n",
            "Collecting chex>=0.0.2\n",
            "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 614 kB/s \n",
            "\u001b[?25hCollecting ml_collections>=0.1\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.14.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from jaxline) (4.1.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.3.14+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.12.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.3.14)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (0.6.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex>=0.0.2->jaxline) (2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml_collections>=0.1->jaxline) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml_collections>=0.1->jaxline) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml_collections>=0.1->jaxline) (0.5.5)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->chex>=0.0.2->jaxline) (5.8.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->chex>=0.0.2->jaxline) (3.8.1)\n",
            "Building wheels for collected packages: jaxline, ml-collections\n",
            "  Building wheel for jaxline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaxline: filename=jaxline-0.0.5-py3-none-any.whl size=33155 sha256=5dbdc95cb075531cf3cfc4ea0e6580a0abd91b60fe672ba0ea6e795fc2eb9aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/a5/24/c294ebcbe11d8b527134a2601c32fcdf14aedb1523454bdc53\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=1aeda4a425a3293ae7af687e8a0c5db092315c41ee967f2c746b37768db1478c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built jaxline ml-collections\n",
            "Installing collected packages: ml-collections, chex, jaxline\n",
            "Successfully installed chex-0.1.3 jaxline-0.0.5 ml-collections-0.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.3)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.14+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.14)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.2.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.6.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.8.0)\n",
            "Installing collected packages: optax\n",
            "Successfully installed optax-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n",
            "/content/perceiver\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-haiku\n",
        "!pip install einops\n",
        "\n",
        "!mkdir /content/perceiver\n",
        "!touch /content/perceiver/__init__.py\n",
        "!wget -O /content/perceiver/io_processors.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
        "!wget -O /content/perceiver/perceiver.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
        "!wget -O /content/perceiver/position_encoding.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py\n",
        "!mkdir /content/perceiver/train \n",
        "!wget -O /content/perceiver/train/autoaugment.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/autoaugment.py\n",
        "!wget -O /content/perceiver/train/dataset.py    https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/dataset.py\n",
        "!wget -O /content/perceiver/experiment.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/experiment.py\n",
        "!wget -O /content/perceiver/train/utils.py  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/utils.py\n",
        "\n",
        "!pip install jaxline\n",
        "!pip install optax\n",
        "!pip install tensorflow-addons\n",
        "\n",
        "%cd perceiver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWHXBdPG23Oe"
      },
      "outputs": [],
      "source": [
        "datafiles = [\"/content/perceiver/perceiver.py\", '/content/perceiver/train/dataset.py', '/content/perceiver/experiment.py' ]\n",
        "\n",
        "def remove_from_per(filename):\n",
        "  # Read in the file\n",
        "  with open(filename, 'r') as file :\n",
        "    filedata = file.read()\n",
        "\n",
        "  # Replace the target string\n",
        "  filedata = filedata.replace('from perceiver ', '')\n",
        "  if ('experiment.py' in filename):\n",
        "    filedata = filedata.replace('PerceiverEncoder', 'perceiver.PerceiverEncoder')\n",
        "    filedata = filedata.replace('ClassificationDecoder', 'perceiver.ClassificationDecoder')\n",
        "    filedata = filedata.replace('Perceiver', 'perceiver.Perceiver')\n",
        "\n",
        "  # Write the file out again\n",
        "  with open(filename, 'w') as file:\n",
        "    file.write(filedata)\n",
        "\n",
        "\n",
        "def remove_from_per_dot(filename):\n",
        "  # Read in the file\n",
        "  with open(filename, 'r') as file :\n",
        "    filedata = file.read()\n",
        "\n",
        "  # Replace the target string\n",
        "  filedata = filedata.replace('perceiver.', '')\n",
        "\n",
        "  # Write the file out again\n",
        "  with open(filename, 'w') as file:\n",
        "    file.write(filedata)\n",
        "\n",
        "def remove_label(filename):\n",
        "  # Read in the file\n",
        "  with open(filename, 'r') as file :\n",
        "    filedata = file.read()\n",
        "\n",
        "  # Replace the target string\n",
        "  filedata = filedata.replace('host_label', 'host_id')\n",
        "  filedata = filedata.replace('imagenet2012:5.*.*', 'oxford_flowers102')\n",
        "  filedata = filedata.replace('1281167', '1020')\n",
        "  filedata = filedata.replace('1271167','1020')\n",
        "  filedata = filedata.replace('10000', '1020')\n",
        "  filedata = filedata.replace('50000', '6149')\n",
        "\n",
        "  # Write the file out again\n",
        "  with open(filename, 'w') as file:\n",
        "    file.write(filedata)\n",
        "\n",
        "remove_from_per(datafiles[0])\n",
        "remove_from_per_dot(datafiles[1])\n",
        "\n",
        "remove_from_per_dot(datafiles[2])\n",
        "remove_from_per(datafiles[2])\n",
        "\n",
        "remove_label('/content/perceiver/train/dataset.py')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Experiment.py \n",
        "\n",
        "import functools\n",
        "from typing import Generator, Mapping, Text, Tuple\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jaxline import base_config\n",
        "from jaxline import experiment\n",
        "from jaxline import platform\n",
        "from jaxline import utils as jl_utils\n",
        "from ml_collections import config_dict\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "\n",
        "import io_processors\n",
        "import perceiver\n",
        "from train import dataset\n",
        "from train import utils\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "OptState = Tuple[optax.TraceState, optax.ScaleByScheduleState, optax.ScaleState]\n",
        "Scalars = Mapping[Text, jnp.ndarray]\n",
        "\n",
        "\n",
        "N_TRAIN_EXAMPLES = dataset.Split.TRAIN_AND_VALID.num_examples\n",
        "N_CLASSES = 600\n",
        "# Only local/debug parameters are supported out of the box.\n",
        "# To use the scaled-up hyperparameters, please adapt this script to your\n",
        "# training setup and set this flag to False\n",
        "IS_LOCAL = True\n",
        "NUM_FRAMES = 16\n",
        "SAMPLES_PER_PATCH = 16\n",
        "NUM_CLASSES = 600\n",
        "IMG_SZ = 56\n",
        "\n",
        "\n",
        "def get_training_steps(batch_size, n_epochs):\n",
        "  return (N_TRAIN_EXAMPLES * n_epochs) // batch_size\n",
        "\n",
        "\n",
        "def get_config():\n",
        "  \"\"\"Return config object for training.\"\"\"\n",
        "  use_debug_settings = IS_LOCAL\n",
        "  config = base_config.get_base_config()\n",
        "\n",
        "  # Experiment config.\n",
        "  local_batch_size = 2\n",
        "  # Modify this to adapt to your custom distributed learning setup\n",
        "  num_devices = 1\n",
        "  config.train_batch_size = local_batch_size * num_devices\n",
        "  config.n_epochs = 110\n",
        "\n",
        "  def _default_or_debug(default_value, debug_value):\n",
        "    return debug_value if use_debug_settings else default_value\n",
        "\n",
        "  n_train_examples = N_TRAIN_EXAMPLES\n",
        "  num_classes = N_CLASSES\n",
        "\n",
        "  config.experiment_kwargs = config_dict.ConfigDict(\n",
        "      dict(\n",
        "          config=dict(\n",
        "              optimizer=dict(\n",
        "                  base_lr=5e-4,\n",
        "                  max_norm=10.0,  # < 0 to turn off.\n",
        "                  schedule_type='constant_cosine',\n",
        "                  weight_decay=1e-1,\n",
        "                  decay_pos_embs=True,\n",
        "                  scale_by_batch=True,\n",
        "                  cosine_decay_kwargs=dict(\n",
        "                      init_value=0.0,\n",
        "                      warmup_epochs=0,\n",
        "                      end_value=0.0,\n",
        "                  ),\n",
        "                  step_decay_kwargs=dict(\n",
        "                      decay_boundaries=[0.5, 0.8, 0.95],\n",
        "                      decay_rate=0.1,\n",
        "                  ),\n",
        "                  constant_cosine_decay_kwargs=dict(\n",
        "                      constant_fraction=0.5,\n",
        "                      end_value=0.0,\n",
        "                  ),\n",
        "                  optimizer='lamb',\n",
        "                  # Optimizer-specific kwargs:\n",
        "                  adam_kwargs=dict(\n",
        "                      b1=0.9,\n",
        "                      b2=0.999,\n",
        "                      eps=1e-8,\n",
        "                  ),\n",
        "                  lamb_kwargs=dict(\n",
        "                      b1=0.9,\n",
        "                      b2=0.999,\n",
        "                      eps=1e-6,\n",
        "                  ),\n",
        "              ),\n",
        "          \n",
        "\n",
        "              model=dict(\n",
        "                  perceiver_kwargs=dict(\n",
        "                      encoder=dict(\n",
        "                        num_self_attends_per_block=8,\n",
        "                        # Weights won't be shared if num_blocks is set to 1.\n",
        "                        num_blocks=1,\n",
        "                        z_index_dim=28*28*1,\n",
        "                        num_z_channels=512,\n",
        "                        num_cross_attend_heads=1,\n",
        "                        num_self_attend_heads=8,\n",
        "                        cross_attend_widening_factor=1,\n",
        "                        self_attend_widening_factor=1,\n",
        "                        dropout_prob=0.0,\n",
        "                        z_pos_enc_init_scale=0.02,\n",
        "                        cross_attention_shape_for_attn='kv',\n",
        "                        name='encoder'\n",
        "                        ),\n",
        "\n",
        "                      decoder=dict(\n",
        "                        # Autoencoding, don't pass inputs to the queries.\n",
        "                        concat_preprocessed_input=False,                        \n",
        "                        # Modality specific decoders are used ONLY to generate queries.\n",
        "                        # All modalties are decoded together using a unified decoder.                       \n",
        "                        num_outputs=None,\n",
        "                        output_num_channels=512,\n",
        "                        use_query_residual=False,\n",
        "                      ),\n",
        "                  ),\n",
        "              ),\n",
        "            \n",
        "              training=dict(\n",
        "                  inputs_per_epoch=n_train_examples,\n",
        "                  label_smoothing=0.1,\n",
        "                  n_epochs=config.get_oneway_ref('n_epochs'),\n",
        "                  batch_size=config.get_oneway_ref('train_batch_size')\n",
        "              ),\n",
        "              data=dict(\n",
        "                  num_classes=num_classes,\n",
        "                  # Run on smaller inputs to debug.\n",
        "                  im_dim=_default_or_debug(224, 32),\n",
        "                  augmentation=dict(\n",
        "                      # Typical randaug params:\n",
        "                      # num_layers in [1, 3]\n",
        "                      # magnitude in [5, 30]\n",
        "                      # Set randaugment to None to disable.\n",
        "                      # randaugment=dict(\n",
        "                      #     num_layers=4,\n",
        "                      #     magnitude=5),\n",
        "                      # cutmix=True,\n",
        "                      # Mixup alpha should be in [0, 1].\n",
        "                      # Set to None to disable.\n",
        "                      # mixup_alpha=0.2,\n",
        "                  ),\n",
        "                  ),\n",
        "              evaluation=dict(\n",
        "                  subset='test',\n",
        "                  batch_size=2,\n",
        "              ),\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # Training loop config.\n",
        "  config.training_steps = get_training_steps(\n",
        "      config.get_oneway_ref('train_batch_size'),\n",
        "      config.get_oneway_ref('n_epochs'))\n",
        "  config.log_train_data_interval = 60\n",
        "  config.log_tensors_interval = 60\n",
        "  config.save_checkpoint_interval = 300\n",
        "  config.eval_specific_checkpoint_dir = ''\n",
        "  config.best_model_eval_metric = 'eval_top_1_acc'\n",
        "  config.checkpoint_dir = '/tmp/perceiver_imagnet_checkpoints'\n",
        "  config.train_checkpoint_all_hosts = False\n",
        "\n",
        "  # Prevents accidentally setting keys that aren't recognized (e.g. in tests).\n",
        "  config.lock()\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "class Experiment(experiment.AbstractExperiment):\n",
        "  \"\"\"ImageNet experiment.\"\"\"\n",
        "\n",
        "  # A map from object properties that will be checkpointed to their name\n",
        "  # in a checkpoint. Currently we assume that these are all sharded\n",
        "  # device arrays.\n",
        "  CHECKPOINT_ATTRS = {\n",
        "      '_params': 'params',\n",
        "      '_state': 'state',\n",
        "      '_opt_state': 'opt_state',\n",
        "  }\n",
        "\n",
        "  def __init__(self, mode, init_rng, config):\n",
        "    \"\"\"Initializes experiment.\"\"\"\n",
        "\n",
        "    super(Experiment, self).__init__(mode=mode, init_rng=init_rng)\n",
        "\n",
        "    self.mode = mode\n",
        "    self.init_rng = init_rng\n",
        "    self.config = config\n",
        "\n",
        "    # Checkpointed experiment state.\n",
        "    self._params = None\n",
        "    self._state = None\n",
        "    self._opt_state = None\n",
        "\n",
        "    # Input pipelines.\n",
        "    self._train_input = None\n",
        "    self._eval_input = None\n",
        "\n",
        "    self.forward = hk.transform_with_state(self._forward_fn)\n",
        "\n",
        "    # NOTE: We \"donate\" the `params, state, opt_state` arguments which allows\n",
        "    # JAX (on some backends) to reuse the device memory associated with these\n",
        "    # inputs to store the outputs of our function (which also start with\n",
        "    # `params, state, opt_state`).\n",
        "    self._update_func = jax.pmap(self._update_func, axis_name='i',\n",
        "                                 donate_argnums=(0, 1, 2))\n",
        "    self._eval_batch = jax.jit(self._eval_batch)\n",
        "\n",
        "  def _forward_fn(\n",
        "      self,\n",
        "      inputs: dataset.Batch,\n",
        "      is_training: bool,\n",
        "      subsampling\n",
        "  ) -> jnp.ndarray:\n",
        "\n",
        "    inputs = inputs['images']\n",
        "    \n",
        "    subsampled_index_dims = {      \n",
        "        'image': subsampling['image'].shape[0],\n",
        "        'label': 1,\n",
        "    }\n",
        "    \n",
        "      \n",
        "    \n",
        "    perceiver_kwargs = self.config.model.perceiver_kwargs\n",
        "    output_postprocessor = io_processors.MultimodalPostprocessor(  modalities={                            \n",
        "            'image': io_processors.ProjectionPostprocessor(\n",
        "                num_outputs=3),\n",
        "            'label': io_processors.ClassificationPostprocessor(\n",
        "                num_classes=NUM_CLASSES),\n",
        "        })\n",
        "    input_preprocessor = io_processors.MultimodalPreprocessor(\n",
        "        min_padding_size=4,        \n",
        "        modalities={      \n",
        "            'image': io_processors.ImagePreprocessor(\n",
        "                position_encoding_type= 'fourier',\n",
        "                fourier_position_encoding_kwargs=dict(\n",
        "                    num_bands=32,\n",
        "                    max_resolution=(NUM_FRAMES, IMG_SZ, IMG_SZ),\n",
        "                    sine_only=False,\n",
        "                    concat_pos=True,\n",
        "                ),\n",
        "                n_extra_pos_mlp=0,\n",
        "                prep_type='patches',\n",
        "                spatial_downsample=4,\n",
        "                temporal_downsample=1),\n",
        "            'label': io_processors.OneHotPreprocessor(),\n",
        "        },\n",
        "        mask_probs={'image': 0.0, 'audio': 0.0, 'label': 1.0},\n",
        "        )\n",
        "    encoder = perceiver.PerceiverEncoder(**perceiver_kwargs['encoder'])\n",
        "    decoder = perceiver.MultimodalDecoder(\n",
        "        subsampled_index_dims=subsampled_index_dims,\n",
        "        modalities={\n",
        "                'image': perceiver.BasicVideoAutoencodingDecoder(\n",
        "                    concat_preprocessed_input=False,\n",
        "                    subsampled_index_dims=subsampling['image'],\n",
        "                    output_shape=inputs.shape[:4],\n",
        "                    num_z_channels=1024,\n",
        "                    output_num_channels=512,\n",
        "                    use_query_residual=False,\n",
        "                    position_encoding_type='fourier',\n",
        "                    fourier_position_encoding_kwargs=dict(\n",
        "                      num_bands=32,\n",
        "                      max_resolution=(NUM_FRAMES, IMG_SZ, IMG_SZ),\n",
        "                      sine_only=False,\n",
        "                      concat_pos=True,\n",
        "                    ),   \n",
        "                ),\n",
        "                'label': perceiver.ClassificationDecoder(\n",
        "                    # Autoencoding, don't pass inputs to the queries.\n",
        "                    concat_preprocessed_input=False,\n",
        "                    num_classes=NUM_CLASSES,\n",
        "                    num_z_channels=1024,\n",
        "                    use_query_residual=False,\n",
        "                    position_encoding_type='trainable',\n",
        "                    trainable_position_encoding_kwargs=dict(\n",
        "                        num_channels=1024,\n",
        "                        init_scale=0.02,\n",
        "                    ),\n",
        "                ),\n",
        "            },\n",
        "        **perceiver_kwargs['decoder'])\n",
        "    \n",
        "    model = perceiver.Perceiver(\n",
        "      input_preprocessor=input_preprocessor,\n",
        "      encoder=encoder,\n",
        "      decoder=decoder,\n",
        "      output_postprocessor=output_postprocessor)\n",
        "\n",
        "    return model({'image': inputs,                \n",
        "                'label': np.zeros((inputs.shape[0], 600))},\n",
        "               is_training=is_training, subsampled_output_points=subsampling)\n",
        "\n",
        "  #  _             _\n",
        "  # | |_ _ __ __ _(_)_ __\n",
        "  # | __| '__/ _` | | '_ \\\n",
        "  # | |_| | | (_| | | | | |\n",
        "  #  \\__|_|  \\__,_|_|_| |_|\n",
        "  #\n",
        "\n",
        "  def step(self, global_step: int, rng: jnp.ndarray,\n",
        "           *unused_args, **unused_kwargs):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "\n",
        "    if self._train_input is None:\n",
        "      self._initialize_train()\n",
        "\n",
        "    inputs = next(self._train_input)\n",
        "\n",
        "    self._params, self._state, self._opt_state, scalars = (\n",
        "        self._update_func(\n",
        "            self._params, self._state, self._opt_state, inputs, rng, global_step\n",
        "            ))\n",
        "\n",
        "    scalars = jl_utils.get_first(scalars)\n",
        "    return scalars\n",
        "\n",
        "  def _initialize_train(self):\n",
        "    self._train_input = jl_utils.py_prefetch(self._build_train_input)\n",
        "\n",
        "    total_batch_size = self.config.training.batch_size\n",
        "    steps_per_epoch = (\n",
        "        self.config.training.inputs_per_epoch / self.config.training.batch_size)\n",
        "    total_steps = self.config.training.n_epochs * steps_per_epoch\n",
        "    # Scale by the (negative) learning rate.\n",
        "    self._lr_schedule = utils.get_learning_rate_schedule(\n",
        "        total_batch_size, steps_per_epoch, total_steps, self.config.optimizer)\n",
        "\n",
        "    self._optimizer = utils.make_optimizer(\n",
        "        self.config.optimizer,\n",
        "        self._lr_schedule)\n",
        "\n",
        "    # Check we haven't already restored params\n",
        "    if self._params is None:\n",
        "      logging.info('Initializing parameters.')\n",
        "\n",
        "      inputs = next(self._train_input)\n",
        "      nchunks = 128\n",
        "      image_chunk_size = np.prod(inputs['images'].shape[1:-1]) // nchunks\n",
        "      subsampling = {\n",
        "            'image': jnp.arange(\n",
        "                image_chunk_size * 0 , image_chunk_size * ( 1)),\n",
        "            \n",
        "            'label': None,\n",
        "        }\n",
        "    \n",
        "      init_net = jax.pmap(lambda *a: self.forward.init(*a,  subsampling=subsampling, is_training=True))\n",
        "      init_opt = jax.pmap(self._optimizer.init)\n",
        "\n",
        "      # Init uses the same RNG key on all hosts+devices to ensure everyone\n",
        "      # computes the same initial state.\n",
        "      init_rng = jl_utils.bcast_local_devices(self.init_rng)\n",
        "\n",
        "      self._params, self._state = init_net(init_rng, inputs)\n",
        "      self._opt_state = init_opt(self._params)\n",
        "\n",
        "  def _load_data(self, split, is_training, batch_dims):\n",
        "    \"\"\"Wrapper for dataset loading.\"\"\"\n",
        "\n",
        "    return dataset.load(\n",
        "        split=split,\n",
        "        is_training=is_training,\n",
        "        batch_dims=batch_dims,\n",
        "        im_dim=self.config.data.im_dim,\n",
        "        augmentation_settings=self.config.data.augmentation,\n",
        "        )\n",
        "\n",
        "  def _build_train_input(self) -> Generator[dataset.Batch, None, None]:\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    num_devices = jax.device_count()\n",
        "    global_batch_size = self.config.training.batch_size\n",
        "    per_device_batch_size, ragged = divmod(global_batch_size, num_devices)\n",
        "\n",
        "    if ragged:\n",
        "      raise ValueError(\n",
        "          f'Global batch size {global_batch_size} must be divisible by '\n",
        "          f'num devices {num_devices}')\n",
        "\n",
        "    split = dataset.Split.TRAIN_AND_VALID\n",
        "\n",
        "    return self._load_data(\n",
        "        split=split,\n",
        "        is_training=True,\n",
        "        batch_dims=[jax.local_device_count(), per_device_batch_size])\n",
        "\n",
        "  def _one_hot(self, value):\n",
        "    \"\"\"One-hot encoding potentially over a sequence of labels.\"\"\"\n",
        "    y = jax.nn.one_hot(value, self.config.data.num_classes)\n",
        "    return y\n",
        "\n",
        "  def _loss_fn(\n",
        "      self,\n",
        "      params: hk.Params,\n",
        "      state: hk.State,\n",
        "      inputs: dataset.Batch,\n",
        "      rng: jnp.ndarray,\n",
        "  ) -> Tuple[jnp.ndarray, Tuple[Scalars, hk.State]]:\n",
        "    nchunks = 128\n",
        "    reconstruction = {}\n",
        "    \n",
        "    for chunk_idx in range(nchunks):\n",
        "        image_chunk_size = np.prod(inputs['images'].shape[1:-1]) // nchunks\n",
        "        \n",
        "        subsampling = {\n",
        "            'image': jnp.arange(\n",
        "                image_chunk_size * chunk_idx, image_chunk_size * (chunk_idx + 1)),\n",
        "           \n",
        "            'label': None,\n",
        "        }\n",
        "        \n",
        "        output, state = self.forward.apply(\n",
        "            params, state, rng, inputs, subsampling=subsampling, is_training=True)\n",
        "    \n",
        "        reconstruction['label'] = output['label']\n",
        "        if 'image' not in reconstruction:\n",
        "            reconstruction['image'] = output['image']\n",
        "            \n",
        "        else:\n",
        "            reconstruction['image'] = jnp.concatenate(\n",
        "                [reconstruction['image'], output['image']], axis=1)\n",
        "          \n",
        "            \n",
        "        reconstruction['image'] = jnp.reshape(reconstruction['image'], inputs['images'].shape)\n",
        "\n",
        "    # label = self._one_hot(inputs['labels'])\n",
        "    # Handle cutmix/mixup label mixing:\n",
        "    # if 'mix_labels' in inputs:\n",
        "    #   logging.info('Using mixup or cutmix!')\n",
        "    #   mix_label = self._one_hot(inputs['mix_labels'])\n",
        "    #   mix_ratio = inputs['ratio'][:, None]\n",
        "    #   label = mix_ratio * label + (1. - mix_ratio) * mix_label\n",
        "\n",
        "    # # Apply label-smoothing to one-hot labels.\n",
        "    # label_smoothing = self.config.training.label_smoothing\n",
        "    # if not (label_smoothing >= 0. and label_smoothing < 1.):\n",
        "    #   raise ValueError(\n",
        "    #       f\"'label_smoothing is {label_smoothing} and should be in [0, 1)\")\n",
        "    # if label_smoothing > 0:\n",
        "    #   smooth_positives = 1. - label_smoothing\n",
        "    #   smooth_negatives = label_smoothing / self.config.data.num_classes\n",
        "    #   label = smooth_positives * label + smooth_negatives\n",
        "\n",
        "\n",
        "######## CHANGE!!!!!!!!!!!!!!! ###################\n",
        "    loss_w_batch = utils.softmax_cross_entropy(output, label)\n",
        "    loss = jnp.mean(loss_w_batch, dtype=loss_w_batch.dtype)\n",
        "    scaled_loss = loss / jax.device_count()\n",
        "\n",
        "    metrics = utils.topk_correct(output, inputs['labels'], prefix='')\n",
        "    metrics = jax.tree_map(jnp.mean, metrics)\n",
        "\n",
        "    top_1_acc = metrics['top_1_acc']\n",
        "    top_5_acc = metrics['top_5_acc']\n",
        "\n",
        "    loss_scalars = dict(\n",
        "        loss=loss,\n",
        "        top_1_acc=top_1_acc,\n",
        "        top_5_acc=top_5_acc,\n",
        "    )\n",
        "\n",
        "    return scaled_loss, (loss_scalars, state)\n",
        "\n",
        "  def _update_func(\n",
        "      self,\n",
        "      params: hk.Params,\n",
        "      state: hk.State,\n",
        "      opt_state: OptState,\n",
        "      inputs: dataset.Batch,\n",
        "      rng: jnp.ndarray,\n",
        "      global_step: int,\n",
        "  ) -> Tuple[hk.Params, hk.State, OptState, Scalars]:\n",
        "    \"\"\"Applies an update to parameters and returns new state.\"\"\"\n",
        "    # This function computes the gradient of the first output of loss_fn and\n",
        "    # passes through the other arguments unchanged.\n",
        "    grad_loss_fn = jax.grad(self._loss_fn, has_aux=True)\n",
        "    scaled_grads, (loss_scalars, state) = grad_loss_fn(\n",
        "        params, state, inputs, rng)\n",
        "    grads = jax.lax.psum(scaled_grads, axis_name='i')\n",
        "\n",
        "    # Grab the learning rate to log before performing the step.\n",
        "    learning_rate = self._lr_schedule(global_step)\n",
        "\n",
        "    # Compute and apply updates via our optimizer.\n",
        "    updates, opt_state = self._optimizer.update(grads, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "\n",
        "    n_params = 0\n",
        "    for k in params.keys():\n",
        "      for l in params[k]:\n",
        "        n_params = n_params + np.prod(params[k][l].shape)\n",
        "\n",
        "    # Scalars to log (note: we log the mean across all hosts/devices).\n",
        "    scalars = {'learning_rate': learning_rate,\n",
        "               'n_params (M)': float(n_params/1e6),\n",
        "               'global_gradient_norm': optax.global_norm(grads)}\n",
        "    loss_scalars = {f'train_{k}': v for k, v in loss_scalars.items()}\n",
        "    scalars.update(loss_scalars)\n",
        "    scalars = jax.lax.pmean(scalars, axis_name='i')\n",
        "\n",
        "    return params, state, opt_state, scalars\n",
        "\n",
        "  #                  _\n",
        "  #   _____   ____ _| |\n",
        "  #  / _ \\ \\ / / _` | |\n",
        "  # |  __/\\ V / (_| | |\n",
        "  #  \\___| \\_/ \\__,_|_|\n",
        "  #\n",
        "\n",
        "  def evaluate(self, global_step, rng, **unused_args):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    global_step = np.array(jl_utils.get_first(global_step))\n",
        "    scalars = jax.device_get(self._eval_epoch(jl_utils.get_first(rng)))\n",
        "\n",
        "    logging.info('[Step %d] Eval scalars: %s', global_step, scalars)\n",
        "    return scalars\n",
        "\n",
        "  def _eval_batch(\n",
        "      self,\n",
        "      params: hk.Params,\n",
        "      state: hk.State,\n",
        "      inputs: dataset.Batch,\n",
        "      rng: jnp.ndarray,\n",
        "  ) -> Scalars:\n",
        "    \"\"\"Evaluates a batch.\"\"\"\n",
        "    nchunks = 128\n",
        "    reconstruction = {}\n",
        "    for chunk_idx in range(nchunks):\n",
        "        image_chunk_size = np.prod(inputs['images'].shape[1:-1]) // nchunks\n",
        "        \n",
        "        subsampling = {\n",
        "            'image': jnp.arange(\n",
        "                image_chunk_size * chunk_idx, image_chunk_size * (chunk_idx + 1)),\n",
        "            \n",
        "            'label': None,\n",
        "        }\n",
        "        output, _ = self.forward.apply(\n",
        "            params, state, rng, inputs, subsampling, is_training=False)\n",
        "        reconstruction['label'] = output['label']\n",
        "        if 'image' not in reconstruction:\n",
        "            reconstruction['image'] = output['image']\n",
        "            # reconstruction['audio'] = output['audio']\n",
        "        else:\n",
        "            reconstruction['image'] = jnp.concatenate(\n",
        "                [reconstruction['image'], output['image']], axis=1)\n",
        "            # reconstruction['audio'] = jnp.concatenate(\n",
        "            #     [reconstruction['audio'], output['audio']], axis=1)\n",
        "        \n",
        "    reconstruction['image'] = jnp.reshape(reconstruction['image'], inputs['images'].shape)\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    ### CHANGE##############\n",
        "\n",
        "    labels = self._one_hot(inputs['labels'])\n",
        "    loss = utils.softmax_cross_entropy(output, labels)\n",
        "\n",
        "    metrics = utils.topk_correct(output, inputs['labels'], prefix='')\n",
        "    metrics = jax.tree_map(jnp.mean, metrics)\n",
        "    top_1_acc = metrics['top_1_acc']\n",
        "    top_5_acc = metrics['top_5_acc']\n",
        "\n",
        "    bs = output.shape[0]\n",
        "\n",
        "    top_1_acc = jnp.expand_dims(top_1_acc, axis=0) * bs\n",
        "    top_5_acc = jnp.expand_dims(top_5_acc, axis=0) * bs\n",
        "\n",
        "    # NOTE: Returned values will be summed and finally divided by num_samples.\n",
        "    return {\n",
        "        'eval_loss': loss,\n",
        "        'eval_top_1_acc': top_1_acc, 'eval_top_5_acc': top_5_acc}\n",
        "\n",
        "  def _build_eval_input(self) -> Generator[dataset.Batch, None, None]:\n",
        "    split = dataset.Split.from_string(self.config.evaluation.subset)\n",
        "\n",
        "    return self._load_data(\n",
        "        split=split,\n",
        "        is_training=False,\n",
        "        batch_dims=[self.config.evaluation.batch_size])\n",
        "\n",
        "  def _eval_epoch(self, rng):\n",
        "    \"\"\"Evaluates an epoch.\"\"\"\n",
        "    num_samples = 0.\n",
        "    summed_scalars = None\n",
        "\n",
        "    params = jl_utils.get_first(self._params)\n",
        "    state = jl_utils.get_first(self._state)\n",
        "\n",
        "    for inputs in self._build_eval_input():\n",
        "      num_samples += inputs['labels'].shape[0]\n",
        "      scalars = self._eval_batch(params, state, inputs, rng)\n",
        "\n",
        "      # Accumulate the sum of scalars for each step.\n",
        "      scalars = jax.tree_map(lambda x: jnp.sum(x, axis=0), scalars)\n",
        "      if summed_scalars is None:\n",
        "        summed_scalars = scalars\n",
        "      else:\n",
        "        summed_scalars = jax.tree_multimap(jnp.add, summed_scalars, scalars)\n",
        "\n",
        "    mean_scalars = jax.tree_map(lambda x: x / num_samples, summed_scalars)\n",
        "    return mean_scalars\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  flags.mark_flag_as_required('config')\n",
        "  app.run(functools.partial(platform.main, Experiment))\n"
      ],
      "metadata": {
        "id": "yQxayNE--CP8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title dataset.py\n",
        "import enum\n",
        "from typing import Any, Generator, Mapping, Optional, Sequence, Text, Tuple\n",
        "import os\n",
        "import jax\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from train import autoaugment\n",
        "\n",
        "\n",
        "Batch = Mapping[Text, np.ndarray]\n",
        "MEAN_RGB = (0.485 * 255, 0.456 * 255, 0.406 * 255)\n",
        "STDDEV_RGB = (0.229 * 255, 0.224 * 255, 0.225 * 255)\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "INPUT_DIM = 224  # The number of pixels in the image resize.\n",
        "\n",
        "\n",
        "class Split(enum.Enum):\n",
        "  \"\"\"ImageNet dataset split.\"\"\"\n",
        "  TRAIN = 1\n",
        "  TRAIN_AND_VALID = 2\n",
        "  VALID = 3\n",
        "  TEST = 4\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, name: Text) -> 'Split':\n",
        "    return {'TRAIN': Split.TRAIN, 'TRAIN_AND_VALID': Split.TRAIN_AND_VALID,\n",
        "            'VALID': Split.VALID, 'VALIDATION': Split.VALID,\n",
        "            'TEST': Split.TEST}[name.upper()]\n",
        "\n",
        "  @property\n",
        "  def num_examples(self):\n",
        "    return {Split.TRAIN_AND_VALID: 40, Split.TRAIN: 40,\n",
        "            Split.VALID: 40, Split.TEST: 40}[self]\n",
        "\n",
        "\n",
        "def load(\n",
        "    split: Split,\n",
        "    *,\n",
        "    is_training: bool,\n",
        "    # batch_dims should be:\n",
        "    # [device_count, per_device_batch_size] or [total_batch_size]\n",
        "    batch_dims: Sequence[int],\n",
        "    augmentation_settings: Mapping[str, Any],\n",
        "    # The shape to which images are resized.\n",
        "    im_dim: int = INPUT_DIM,\n",
        "    threadpool_size: int = 48,\n",
        "    max_intra_op_parallelism: int = 1,\n",
        ") -> Generator[Batch, None, None]:\n",
        "  \"\"\"Loads the given split of the dataset.\"\"\"\n",
        "  # start, end = _shard(split, jax.host_id(), jax.process_count())\n",
        "  \n",
        "  im_size = (im_dim, im_dim)\n",
        "\n",
        "  total_batch_size = np.prod(batch_dims)\n",
        "  full_list = []\n",
        "  if (split == Split.TRAIN or split == Split.TRAIN_AND_VALID ):\n",
        "    path = '/content/dataset/train'\n",
        "    filenames_list = os.listdir(path)    \n",
        "  elif (split == Split.VALID):\n",
        "      path = '/content/dataset/valid'\n",
        "      filenames_list  = os.listdir(path)      \n",
        "  else:\n",
        "      path = '/content/dataset/test'\n",
        "      filenames_list  = os.listdir(path)\n",
        "\n",
        "  for file in filenames_list:\n",
        "    full_list.append(os.path.join(path,file))\n",
        "\n",
        "      \n",
        "  ds = dataset_numpy(full_list)\n",
        "  options = tf.data.Options()\n",
        "  options.threading.private_threadpool_size = threadpool_size\n",
        "  options.threading.max_intra_op_parallelism = (\n",
        "      max_intra_op_parallelism)\n",
        "  options.experimental_optimization.map_parallelization = True\n",
        "  if is_training:\n",
        "    options.experimental_deterministic = False\n",
        "  ds = ds.with_options(options)\n",
        "\n",
        "  if is_training:\n",
        "    if jax.process_count() > 1:\n",
        "      # Only cache if we are reading a subset of the dataset.\n",
        "      ds = ds.cache()\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.shuffle(buffer_size=10 * total_batch_size, seed=0)\n",
        "\n",
        "  else:\n",
        "    if split.num_examples % total_batch_size != 0:\n",
        "      raise ValueError(f'Test/vallabel must be divisible by {total_batch_size}')\n",
        "\n",
        "  def crop_augment_preprocess(example):\n",
        "    image = example #_preprocess_image(example['image'], is_training, im_size, augmentation_settings)\n",
        "    label_init = random.randint(0, 600)\n",
        "    label = tf.cast(label_init, tf.int32)\n",
        "    out = {'images': image, 'labels': label}\n",
        "    return out\n",
        "\n",
        "  ds = ds.map(crop_augment_preprocess, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  for batch_size in reversed(batch_dims):\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "\n",
        "  yield from tfds.as_numpy(ds)\n",
        "\n",
        "\n",
        "def dataset_numpy(filenames_list):\n",
        "    if filenames_list :\n",
        "        # initialize train dataset\n",
        "        train_dataset = np.expand_dims(np.load(filenames_list[0]),axis=0 )\n",
        "        print(\"init shape: \", train_dataset.shape)\n",
        "        ds = tf.data.Dataset.from_tensor_slices(train_dataset)    \n",
        "        print(\"read frist file: \", ds)\n",
        "        # concatenate with the remaining files  \n",
        "        for file in filenames_list[1:]: \n",
        "            read_data = np.expand_dims(np.load(file),axis=0 )\n",
        "\n",
        "            add_ds = tf.data.Dataset.from_tensor_slices((read_data))\n",
        "            ds = ds.concatenate(add_ds)\n",
        "        return ds \n",
        "    else:\n",
        "        print(\"empty list\")\n",
        "    \n"
      ],
      "metadata": {
        "id": "GA3xXbrp-G74",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbWMtR9J4LgX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1786208-7e07-4beb-96f7-b1d802572f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-estimator-2.9.0 tensorflow-gpu-2.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jaxline in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: ml-collections>=0.1 in /usr/local/lib/python3.7/dist-packages (from jaxline) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from jaxline) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from jaxline) (1.14.1)\n",
            "Requirement already satisfied: chex>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from jaxline) (0.1.3)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.3.14+cuda11.cudnn805)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.3.14)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.2->jaxline) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (0.6.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.2->jaxline) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex>=0.0.2->jaxline) (1.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections>=0.1->jaxline) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections>=0.1->jaxline) (3.13)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections>=0.1->jaxline) (0.5.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->chex>=0.0.2->jaxline) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->chex>=0.0.2->jaxline) (5.8.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall tensorflow-io\n",
        "!pip install tensorflow-gpu\n",
        "!pip install --no-deps tensorflow-io\n",
        "!pip install jaxline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy dataset\n"
      ],
      "metadata": {
        "id": "bBvmqtY8agG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np \n",
        "paths = ['/content/dataset/train','/content/dataset/test', '/content/dataset/valid']\n",
        "if (not os.path.exists('/content/dataset')):\n",
        "  os.mkdir('/content/dataset')\n",
        "for subdir in paths:\n",
        "  if (not os.path.exists(subdir)):\n",
        "    os.mkdir(subdir)\n",
        "  for i in range(40):\n",
        "    video = np.random.rand(16,224,224,3)\n",
        "    path = os.path.join(subdir, str(i))\n",
        "    np.save(path, video)\n"
      ],
      "metadata": {
        "id": "FnMhe33q_Ryy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.load('/content/dataset/test/0.npy')\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBfO_Z9ssvJ4",
        "outputId": "320fa24d-9891-4df8-dff4-309c1a57e342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Pre-trained Autoencoder\n",
        "\n",
        "\n",
        "\n",
        "[Colab original code](https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/perceiver/colabs/video_autoencoding.ipynb#scrollTo=uxeP5yit7hJg)\n",
        "\n",
        "[Github for perceiver - all files and examples](https://github.com/deepmind/deepmind-research/tree/master/perceiver)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pgPwY8ZX9D6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "kcpT2gjsWoav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "id": "a4PoeCkpYAHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.htm"
      ],
      "metadata": {
        "id": "FXrgyRKkYNfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "print(\"jax backend {}\".format(jax.lib.xla_bridge.get_backend().platform))\n",
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veUTkbzxZe8b",
        "outputId": "922b6a48-c234-4691-dd19-0d34e64ef686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax backend cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CpuDevice(id=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All GPU devices: \", tf.config.list_logical_devices('GPU'))\n",
        "print(\"All TPU devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM8Y-BNJbkbw",
        "outputId": "56b150a9-86f1-402c-aaad-172130ed0ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All GPU devices:  []\n",
            "All TPU devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U jaxlib==0.3.14+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "l4YZZ_Q3A4M4",
        "outputId": "014720e0-f0d6-40f8-a3b2-fd7ad27183f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jaxlib==0.3.14+cuda11.cudnn82\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.14%2Bcuda11.cudnn82-cp37-none-manylinux2014_x86_64.whl (161.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 161.9 MB 64 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.14+cuda11.cudnn82) (1.12)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.14+cuda11.cudnn82) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.14+cuda11.cudnn82) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.14+cuda11.cudnn82) (1.7.3)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.14+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.14+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.14+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.3.14+cuda11.cudnn82\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jaxlib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kYDroa6jC4-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbgEMoUEcbl"
      },
      "source": [
        "# RUN \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDs9ofApS6Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b474c3ea-4cfe-4708-8e08-d1d800ccac5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "2022-07-24 16:19:23.605808: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "WARNING:tensorflow:TPU system grpc://10.57.100.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "W0724 16:19:55.372099 140215549192064 tpu_strategy_util.py:79] TPU system grpc://10.57.100.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "I0724 16:20:07.394977 140215549192064 train.py:73] Training with config:\n",
            "best_model_eval_metric: eval_top_1_acc\n",
            "best_model_eval_metric_higher_is_better: true\n",
            "checkpoint_dir: /tmp/perceiver_imagnet_checkpoints\n",
            "checkpoint_interval_type: null\n",
            "eval_initial_weights: false\n",
            "eval_specific_checkpoint_dir: ''\n",
            "experiment_kwargs:\n",
            "  config:\n",
            "    data:\n",
            "      augmentation: {}\n",
            "      im_dim: 32\n",
            "      num_classes: 600\n",
            "    evaluation: {batch_size: 2, subset: test}\n",
            "    model:\n",
            "      perceiver_kwargs:\n",
            "        decoder: {concat_preprocessed_input: false, num_outputs: null, output_num_channels: 512,\n",
            "          use_query_residual: false}\n",
            "        encoder: {cross_attend_widening_factor: 1, cross_attention_shape_for_attn: kv,\n",
            "          dropout_prob: 0.0, name: encoder, num_blocks: 1, num_cross_attend_heads: 1,\n",
            "          num_self_attend_heads: 8, num_self_attends_per_block: 8, num_z_channels: 512,\n",
            "          self_attend_widening_factor: 1, z_index_dim: 784, z_pos_enc_init_scale: 0.02}\n",
            "    optimizer:\n",
            "      adam_kwargs: {b1: 0.9, b2: 0.999, eps: 1.0e-08}\n",
            "      base_lr: 0.0005\n",
            "      constant_cosine_decay_kwargs: {constant_fraction: 0.5, end_value: 0.0}\n",
            "      cosine_decay_kwargs: {end_value: 0.0, init_value: 0.0, warmup_epochs: 0}\n",
            "      decay_pos_embs: true\n",
            "      lamb_kwargs: {b1: 0.9, b2: 0.999, eps: 1.0e-06}\n",
            "      max_norm: 10.0\n",
            "      optimizer: lamb\n",
            "      scale_by_batch: true\n",
            "      schedule_type: constant_cosine\n",
            "      step_decay_kwargs:\n",
            "        decay_boundaries: [0.5, 0.8, 0.95]\n",
            "        decay_rate: 0.1\n",
            "      weight_decay: 0.1\n",
            "    training: {batch_size: 2, inputs_per_epoch: 40, label_smoothing: 0.1, n_epochs: 110}\n",
            "interval_type: secs\n",
            "log_all_train_data: false\n",
            "log_tensors_interval: 60\n",
            "log_train_data_interval: 60.0\n",
            "logging_interval_type: null\n",
            "max_checkpoints_to_keep: 5\n",
            "n_epochs: 110\n",
            "one_off_evaluate: false\n",
            "random_mode_eval: same_host_same_device\n",
            "random_mode_train: unique_host_unique_device\n",
            "random_seed: 42\n",
            "save_checkpoint_interval: 300\n",
            "train_batch_size: 2\n",
            "train_checkpoint_all_hosts: false\n",
            "training_steps: 2200\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/lib/xla_bridge.py:507: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "I0724 16:20:07.404331 140215549192064 xla_bridge.py:333] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
            "2022-07-24 16:20:07.411817: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "I0724 16:20:07.412018 140215549192064 xla_bridge.py:333] Unable to initialize backend 'cuda': FAILED_PRECONDITION: No visible GPU devices.\n",
            "I0724 16:20:07.412331 140215549192064 xla_bridge.py:333] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Host Interpreter CUDA\n",
            "I0724 16:20:07.412655 140215549192064 xla_bridge.py:333] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
            "W0724 16:20:07.412745 140215549192064 xla_bridge.py:340] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "I0724 16:20:07.490374 140215549192064 utils.py:299] [jaxline] experiment init starting...\n",
            "I0724 16:20:07.491209 140215549192064 utils.py:306] [jaxline] experiment init finished.\n",
            "I0724 16:20:07.517797 140215549192064 utils.py:299] [jaxline] training loop starting...\n",
            "I0724 16:20:07.518239 140215549192064 experiment.py:358] Initializing parameters.\n",
            "init shape:  (1, 16, 224, 224, 3)\n",
            "read frist file:  <TensorSliceDataset element_spec=TensorSpec(shape=(16, 224, 224, 3), dtype=tf.float64, name=None)>\n",
            "E0724 16:21:19.803086 140215549192064 utils.py:304] [jaxline] training loop failed with error.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/basic.py\", line 183, in __call__\n",
            "    out = out + b\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 570, in __add__\n",
            "    def __add__(self, other): return self.aval._add(self, other)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\", line 4586, in deferring_binary_op\n",
            "    return binary_op(self, other)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 525, in cache_miss\n",
            "    donated_invars=donated_invars, inline=inline, keep_unused=keep_unused)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1836, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1852, in call_bind\n",
            "    outs = top_trace.process_call(primitive, fun_, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 338, in process_call\n",
            "    result = call_primitive.bind(f_jvp, *primals, *nonzero_tangents, **new_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1836, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1852, in call_bind\n",
            "    outs = top_trace.process_call(primitive, fun_, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 230, in process_call\n",
            "    staged_params = dict(params, call_jaxpr=convert_constvars_jaxpr(jaxpr))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/utils.py\", line 301, in log_activity\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/experiment.py\", line 172, in train_loop\n",
            "    global_step=global_step_devices, rng=step_key, writer=writer)\n",
            "  File \"/content/perceiver/experiment.py\", line 335, in step\n",
            "    self._params, self._state, self._opt_state, inputs, rng, global_step\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2144, in cache_miss\n",
            "    out_tree, out_flat = f_pmapped_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2026, in pmap_f\n",
            "    global_arg_shapes=p.global_arg_shapes_flat)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1939, in bind\n",
            "    return map_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1971, in map_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1942, in process\n",
            "    return trace.process_map(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 683, in process_call\n",
            "    return primitive.impl(f, *tracers, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 832, in xla_pmap_impl\n",
            "    *abstract_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 286, in memoized_fun\n",
            "    ans = call(fun, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 859, in parallel_callable\n",
            "    in_axes, out_axes_thunk, donated_invars, global_arg_shapes, avals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 1031, in lower_parallel_callable\n",
            "    pci, fun, global_arg_shapes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 938, in stage_parallel_callable\n",
            "    fun, global_sharded_avals, pe.debug_info_final(fun, \"pmap\"))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 1947, in trace_to_jaxpr_final\n",
            "    fun, main, in_avals, keep_inputs=keep_inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 1892, in trace_to_subjaxpr_dynamic\n",
            "    ans = fun.call_wrapped(*in_tracers_)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 168, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/content/perceiver/experiment.py\", line 500, in _update_func\n",
            "    params, state, inputs, rng)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 993, in grad_f_aux\n",
            "    (_, aux), g = value_and_grad_f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 1066, in value_and_grad_f\n",
            "    f_partial, *dyn_args, has_aux=True, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2564, in _vjp\n",
            "    flat_fun, primals_flat, has_aux=True, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 135, in vjp\n",
            "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 122, in linearize\n",
            "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 621, in trace_to_jaxpr_nounits\n",
            "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 168, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/content/perceiver/experiment.py\", line 435, in _loss_fn\n",
            "    params, state, rng, inputs, subsampling=subsampling, is_training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/transform.py\", line 354, in apply_fn\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/content/perceiver/experiment.py\", line 315, in _forward_fn\n",
            "    is_training=is_training, subsampled_output_points=subsampling)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 377, in __call__\n",
            "    is_training=is_training, input_mask=input_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 468, in __call__\n",
            "    attention_mask=attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 316, in __call__\n",
            "    attention_mask=attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 162, in __call__\n",
            "    k = conv_1d(self._qk_channels, init_scale=self._init_scale)(inputs_kv)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/basic.py\", line 183, in __call__\n",
            "    out = out + b\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 570, in __add__\n",
            "    def __add__(self, other): return self.aval._add(self, other)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\", line 4586, in deferring_binary_op\n",
            "    return binary_op(self, other)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 525, in cache_miss\n",
            "    donated_invars=donated_invars, inline=inline, keep_unused=keep_unused)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1836, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1852, in call_bind\n",
            "    outs = top_trace.process_call(primitive, fun_, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 338, in process_call\n",
            "    result = call_primitive.bind(f_jvp, *primals, *nonzero_tangents, **new_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1836, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1852, in call_bind\n",
            "    outs = top_trace.process_call(primitive, fun_, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 230, in process_call\n",
            "    staged_params = dict(params, call_jaxpr=convert_constvars_jaxpr(jaxpr))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/perceiver/experiment.py\", line 629, in <module>\n",
            "    app.run(functools.partial(platform.main, Experiment))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/utils.py\", line 484, in inner_wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/platform.py\", line 132, in main\n",
            "    train.train(experiment_class, config, checkpointer, writer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/utils.py\", line 620, in inner_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/train.py\", line 123, in train\n",
            "    experiment.train_loop(config, state, periodic_actions, writer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jaxline/experiment.py\", line 172, in train_loop\n",
            "    global_step=global_step_devices, rng=step_key, writer=writer)\n",
            "  File \"/content/perceiver/experiment.py\", line 335, in step\n",
            "    self._params, self._state, self._opt_state, inputs, rng, global_step\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2144, in cache_miss\n",
            "    out_tree, out_flat = f_pmapped_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2026, in pmap_f\n",
            "    global_arg_shapes=p.global_arg_shapes_flat)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1939, in bind\n",
            "    return map_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1971, in map_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1942, in process\n",
            "    return trace.process_map(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 683, in process_call\n",
            "    return primitive.impl(f, *tracers, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 832, in xla_pmap_impl\n",
            "    *abstract_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 286, in memoized_fun\n",
            "    ans = call(fun, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 859, in parallel_callable\n",
            "    in_axes, out_axes_thunk, donated_invars, global_arg_shapes, avals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 1031, in lower_parallel_callable\n",
            "    pci, fun, global_arg_shapes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 938, in stage_parallel_callable\n",
            "    fun, global_sharded_avals, pe.debug_info_final(fun, \"pmap\"))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 1947, in trace_to_jaxpr_final\n",
            "    fun, main, in_avals, keep_inputs=keep_inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 1892, in trace_to_subjaxpr_dynamic\n",
            "    ans = fun.call_wrapped(*in_tracers_)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 168, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/content/perceiver/experiment.py\", line 500, in _update_func\n",
            "    params, state, inputs, rng)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 993, in grad_f_aux\n",
            "    (_, aux), g = value_and_grad_f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 1066, in value_and_grad_f\n",
            "    f_partial, *dyn_args, has_aux=True, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2564, in _vjp\n",
            "    flat_fun, primals_flat, has_aux=True, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 135, in vjp\n",
            "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 122, in linearize\n",
            "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\", line 312, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 621, in trace_to_jaxpr_nounits\n",
            "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 168, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/content/perceiver/experiment.py\", line 435, in _loss_fn\n",
            "    params, state, rng, inputs, subsampling=subsampling, is_training=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/transform.py\", line 354, in apply_fn\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/content/perceiver/experiment.py\", line 315, in _forward_fn\n",
            "    is_training=is_training, subsampled_output_points=subsampling)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 377, in __call__\n",
            "    is_training=is_training, input_mask=input_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 468, in __call__\n",
            "    attention_mask=attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 316, in __call__\n",
            "    attention_mask=attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 271, in run_interceptors\n",
            "    return bound_method(*args, **kwargs)\n",
            "  File \"/content/perceiver/perceiver.py\", line 162, in __call__\n",
            "    k = conv_1d(self._qk_channels, init_scale=self._init_scale)(inputs_kv)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\", line 421, in wrapped\n",
            "    out = f(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "KeyboardInterrupt\n",
            "2022-07-24 16:21:23.748958: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: File system scheme '[local]' not implemented (file: '/tmp/perceiver_imagnet_checkpoints/train')\n",
            "\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.\n"
          ]
        }
      ],
      "source": [
        "!python /content/perceiver/experiment.py --config=/content/perceiver/experiment.py  --logtostderr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTvgHONhThWI"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/perceiver_working.zip /content/perceiver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "ds = tfds.load(name=\"mnist\", split=\"train\")\n",
        "ds_numpy = tfds.as_numpy(ds)  # Convert `tf.data.Dataset` to Python generator\n",
        "for ex in ds_numpy:\n",
        "  # `{'image': np.array(shape=(28, 28, 1)), 'labels': np.array(shape=())}`\n",
        "  # print(ex)\n",
        "  print(ex.keys())\n",
        "  \n",
        "  print(ex.values())\n"
      ],
      "metadata": {
        "id": "nEkKXd0g4Ham"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5boMmgZd5GUY",
        "outputId": "edafa524-c4ca-4d75-d768-76478d3cf09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "from typing import Any, Generator, Mapping, Optional, Sequence, Text, Tuple\n",
        "import os\n",
        "import jax\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "Batch = Mapping[Text, np.ndarray]\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def load(\n",
        "    split: str,\n",
        "    *,\n",
        "    is_training: bool,\n",
        "    # batch_dims should be:\n",
        "    # [device_count, per_device_batch_size] or [total_batch_size]\n",
        "    batch_dims: Sequence[int],   \n",
        "    # The shape to which images are resized.\n",
        "    # im_dim: int = INPUT_DIM,\n",
        "    threadpool_size: int = 48,\n",
        "    max_intra_op_parallelism: int = 1,\n",
        ") -> Generator[Batch, None, None]:\n",
        "  \"\"\"Loads the given split of the dataset.\"\"\"\n",
        "  # start, end = _shard(split, jax.host_id(), jax.process_count())\n",
        "  \n",
        "  # im_size = (16,im_dim, im_dim)\n",
        "\n",
        "  total_batch_size = np.prod(batch_dims)\n",
        "  full_list = []\n",
        "  if (split == \"train\"  ):\n",
        "    path = '/content/dataset_img/train_img'\n",
        "    filenames_list = os.listdir(path)    \n",
        "  elif (split == \"VALID\"):\n",
        "      path = '/content/dataset_img/valid_img'\n",
        "      filenames_list  = os.listdir(path)      \n",
        "  else:\n",
        "      path = '/content/dataset/test'\n",
        "      filenames_list  = os.listdir(path)\n",
        "\n",
        "  for file in filenames_list:\n",
        "    full_list.append(os.path.join(path,file))\n",
        "\n",
        "      \n",
        "  ds = dataset_numpy(full_list)\n",
        "  options = tf.data.Options()\n",
        "  options.threading.private_threadpool_size = threadpool_size\n",
        "  options.threading.max_intra_op_parallelism = (\n",
        "      max_intra_op_parallelism)\n",
        "  options.experimental_optimization.map_parallelization = True\n",
        "  if is_training:\n",
        "    options.experimental_deterministic = False\n",
        "  ds = ds.with_options(options)\n",
        "\n",
        "  if is_training:\n",
        "    if jax.process_count() > 1:\n",
        "      # Only cache if we are reading a subset of the dataset.\n",
        "      ds = ds.cache()\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.shuffle(buffer_size=10 * total_batch_size, seed=0)\n",
        "\n",
        "  else:\n",
        "    if split.num_examples % total_batch_size != 0:\n",
        "      raise ValueError(f'Test/vallabel must be divisible by {total_batch_size}')\n",
        "\n",
        "  def crop_augment_preprocess(example):\n",
        "    print(\"shape: \", example.shape)\n",
        "    image = example #_preprocess_image(example['image'], is_training, im_size, augmentation_settings)\n",
        "    label_init = random.randint(0, 600)\n",
        "    label = tf.cast(label_init, tf.int32)\n",
        "    out = {'images': image, 'labels': label}\n",
        "    return out\n",
        "\n",
        "  ds = ds.map(crop_augment_preprocess, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  for batch_size in reversed(batch_dims):\n",
        "    ds = ds.batch(batch_size)\n",
        "  print(ds)\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "  \n",
        "  yield from tfds.as_numpy(ds)\n",
        "\n",
        "\n",
        "def dataset_numpy(filenames_list):\n",
        "    if filenames_list :\n",
        "        # initialize train dataset\n",
        "        train_dataset = np.expand_dims(np.load(filenames_list[0]),axis=0 )\n",
        "        print(\"init shape: \", train_dataset.shape)\n",
        "        ds = tf.data.Dataset.from_tensor_slices(train_dataset)    \n",
        "        print(\"read frist file: \", ds)\n",
        "        # concatenate with the remaining files  \n",
        "        for file in filenames_list[1:]: \n",
        "            read_data = np.expand_dims(np.load(file),axis=0 )\n",
        "\n",
        "            add_ds = tf.data.Dataset.from_tensor_slices((read_data))\n",
        "            ds = ds.concatenate(add_ds)\n",
        "        return ds \n",
        "    else:\n",
        "        print(\"empty list\")\n",
        "     "
      ],
      "metadata": {
        "id": "LGR-alNu5dyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = load(split='train', is_training=True,batch_dims=[32])\n",
        "for gen in g:\n",
        "  print(gen['images'].shape) \n",
        "  break"
      ],
      "metadata": {
        "id": "M0KtG4nZyNnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77f71ef-cdb7-4891-c253-e42b18aa9821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init shape:  (1, 224, 224, 3)\n",
            "read frist file:  <TensorSliceDataset element_spec=TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None)>\n",
            "shape:  (224, 224, 3)\n",
            "<BatchDataset element_spec={'images': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float64, name=None), 'labels': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}>\n",
            "(32, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset/valid_img\n"
      ],
      "metadata": {
        "id": "GGki0o4GYdoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "pgPwY8ZX9D6j"
      ],
      "name": "WORKING_of Perceiver_change_classifier.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}